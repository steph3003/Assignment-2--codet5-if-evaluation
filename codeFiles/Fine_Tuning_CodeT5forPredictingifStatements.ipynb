{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuVrRxyVfHV9",
        "outputId": "945c195e-4526-4746-883b-4d0105f9e670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: codebleu in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Collecting tree-sitter<0.23.0,>=0.22.0 (from codebleu)\n",
            "  Using cached tree_sitter-0.22.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: setuptools>=61.0.0 in /usr/local/lib/python3.11/dist-packages (from codebleu) (75.2.0)\n",
            "Using cached tree_sitter-0.22.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (544 kB)\n",
            "Installing collected packages: tree-sitter\n",
            "  Attempting uninstall: tree-sitter\n",
            "    Found existing installation: tree_sitter 0.2.0\n",
            "    Uninstalling tree_sitter-0.2.0:\n",
            "      Successfully uninstalled tree_sitter-0.2.0\n",
            "Successfully installed tree-sitter-0.22.3\n",
            "Requirement already satisfied: tree-sitter-python in /usr/local/lib/python3.11/dist-packages (0.23.6)\n",
            "fatal: destination path 'CodeXGLUE' already exists and is not an empty directory.\n",
            "/content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU\n",
            "Collecting tree_sitter==0.2.0\n",
            "  Using cached tree_sitter-0.2.0-cp311-cp311-linux_x86_64.whl\n",
            "Installing collected packages: tree_sitter\n",
            "  Attempting uninstall: tree_sitter\n",
            "    Found existing installation: tree-sitter 0.22.3\n",
            "    Uninstalling tree-sitter-0.22.3:\n",
            "      Successfully uninstalled tree-sitter-0.22.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "codebleu 0.7.0 requires tree-sitter<0.23.0,>=0.22.0, but you have tree-sitter 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tree_sitter-0.2.0\n",
            "/content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/parser\n",
            "fatal: destination path 'tree-sitter-php' already exists and is not an empty directory.\n",
            "fatal: destination path 'tree-sitter-go' already exists and is not an empty directory.\n",
            "fatal: destination path 'tree-sitter-javascript' already exists and is not an empty directory.\n",
            "fatal: destination path 'tree-sitter-python' already exists and is not an empty directory.\n",
            "fatal: destination path 'tree-sitter-ruby' already exists and is not an empty directory.\n",
            "fatal: destination path 'tree-sitter-php' already exists and is not an empty directory.\n",
            "fatal: destination path 'tree-sitter-java' already exists and is not an empty directory.\n",
            "fatal: destination path 'tree-sitter-c-sharp' already exists and is not an empty directory.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/parser/build.py\", line 6, in <module>\n",
            "    Language.build_library(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tree_sitter/__init__.py\", line 41, in build_library\n",
            "    source_mtimes = [path.getmtime(__file__)] + [\n",
            "                                                ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tree_sitter/__init__.py\", line 42, in <listcomp>\n",
            "    path.getmtime(path_) for path_ in source_paths\n",
            "    ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen genericpath>\", line 55, in getmtime\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'tree-sitter-php/src/parser.c'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets sacrebleu torch evaluate\n",
        "!pip install codebleu\n",
        "!pip install tree-sitter-python\n",
        "!git clone https://github.com/microsoft/CodeXGLUE.git\n",
        "%cd CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU\n",
        "!pip install tree_sitter==0.2.0\n",
        "#build parser\n",
        "%cd parser\n",
        "!git clone https://github.com/tree-sitter/tree-sitter-php\n",
        "!bash build.sh\n",
        "%cd /content\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from transformers import RobertaTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from evaluate import load as load_metric\n",
        "import subprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------- Load and Prepare Data ----------#\n",
        "\n",
        "train = pd.read_csv(\"/content/ft_train.csv\")\n",
        "valid = pd.read_csv(\"/content/ft_valid.csv\")\n",
        "test = pd.read_csv(\"/content/ft_test.csv\")\n",
        "\n",
        "def mask_if_condition(row):\n",
        "    \"\"\"Replace the target_block line in cleaned_method with <mask> and flatten the function.\"\"\"\n",
        "    target = row['target_block'].strip()\n",
        "    method = row['cleaned_method']\n",
        "\n",
        "    # Escape special characters in regex pattern\n",
        "    escaped_target = re.escape(target)\n",
        "\n",
        "    # Replace only the first occurrence of the if statement with <mask>\n",
        "    masked_method = re.sub(escaped_target, '<mask>', method, count=1)\n",
        "\n",
        "    # Flatten: Remove newlines, tabs, and excessive spaces\n",
        "    flattened = \" \".join(masked_method.strip().split())\n",
        "\n",
        "    return flattened\n",
        "\n",
        "# Apply to all datasets\n",
        "for df in [train, valid, test]:\n",
        "    df['masked_method'] = df.apply(mask_if_condition, axis=1)\n",
        "\n",
        "\n",
        "# Preview one\n",
        "train[['cleaned_method', 'target_block', 'masked_method']].head()"
      ],
      "metadata": {
        "id": "GMSyoFy6qcZZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0f3606bc-c2aa-4c47-835f-dae08580f0cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      cleaned_method  \\\n",
              "0  def _resolve_lib_imported_symbols(self, lib, i...   \n",
              "1  def make_docs_directory(output_dir, name):\\n  ...   \n",
              "2  def assert_results(self, results, activities, ...   \n",
              "3  def for_file(cls, filename: str, modname: str)...   \n",
              "4  def merge_dicts(source: Dict, destination: Dic...   \n",
              "\n",
              "                                        target_block  \\\n",
              "0                                  if generic_refs :   \n",
              "1  if not isdir ( pjoin ( output_dir , name , str...   \n",
              "2          if hasattr ( result , \"extra_context\" ) :   \n",
              "3               if \".egg\" + path . sep in filename :   \n",
              "4                   if isinstance ( value , dict ) :   \n",
              "\n",
              "                                       masked_method  \n",
              "0  def _resolve_lib_imported_symbols(self, lib, i...  \n",
              "1  def make_docs_directory(output_dir, name): if ...  \n",
              "2  def assert_results(self, results, activities, ...  \n",
              "3  def for_file(cls, filename: str, modname: str)...  \n",
              "4  def merge_dicts(source: Dict, destination: Dic...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8b16fef-09a0-4ce0-b978-92234a8b257c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_method</th>\n",
              "      <th>target_block</th>\n",
              "      <th>masked_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>def _resolve_lib_imported_symbols(self, lib, i...</td>\n",
              "      <td>if generic_refs :</td>\n",
              "      <td>def _resolve_lib_imported_symbols(self, lib, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>def make_docs_directory(output_dir, name):\\n  ...</td>\n",
              "      <td>if not isdir ( pjoin ( output_dir , name , str...</td>\n",
              "      <td>def make_docs_directory(output_dir, name): if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>def assert_results(self, results, activities, ...</td>\n",
              "      <td>if hasattr ( result , \"extra_context\" ) :</td>\n",
              "      <td>def assert_results(self, results, activities, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>def for_file(cls, filename: str, modname: str)...</td>\n",
              "      <td>if \".egg\" + path . sep in filename :</td>\n",
              "      <td>def for_file(cls, filename: str, modname: str)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>def merge_dicts(source: Dict, destination: Dic...</td>\n",
              "      <td>if isinstance ( value , dict ) :</td>\n",
              "      <td>def merge_dicts(source: Dict, destination: Dic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8b16fef-09a0-4ce0-b978-92234a8b257c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8b16fef-09a0-4ce0-b978-92234a8b257c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8b16fef-09a0-4ce0-b978-92234a8b257c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-195aa889-1a22-45b7-ad66-e4dbeebc8a96\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-195aa889-1a22-45b7-ad66-e4dbeebc8a96')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-195aa889-1a22-45b7-ad66-e4dbeebc8a96 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train[['cleaned_method', 'target_block', 'masked_method']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"cleaned_method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"def make_docs_directory(output_dir, name):\\n    if not isdir(pjoin(output_dir, name)):\\n        subprocess.run([\\\"mkdir\\\", pjoin(output_dir, name)], stdout=subprocess.PIPE)\\n    for i in range(10):\\n        if not isdir(pjoin(output_dir, name, str(i))):\\n            subprocess.run(\\n                [\\\"mkdir\\\", pjoin(output_dir, name, str(i))], stdout=subprocess.PIPE\\n            )\\n\",\n          \"def merge_dicts(source: Dict, destination: Dict) -> Dict:\\n    for key, value in source.items():\\n        if isinstance(value, dict):\\n            # get node or create one\\n            node = destination.setdefault(key, {})\\n            merge_dicts(value, node)\\n        else:\\n            destination[key] = value\\n    return destination\\n\",\n          \"def assert_results(self, results, activities, msg=\\\"\\\"):\\n    activity_ids = []\\n    extra_context = []\\n    for result in results:\\n        if hasattr(result, \\\"serialization_id\\\"):\\n            activity_ids.append(result.serialization_id)\\n        else:\\n            activity_ids.append(result)\\n        if hasattr(result, \\\"extra_context\\\"):\\n            extra_context.append(result.extra_context)\\n    compare_lists(activity_ids, [a.serialization_id for a in activities], msg)\\n    if extra_context:\\n        self.assertEquals([a.extra_context for a in activities], extra_context)\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_block\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"if not isdir ( pjoin ( output_dir , name , str ( i ) ) ) :\",\n          \"if isinstance ( value , dict ) :\",\n          \"if hasattr ( result , \\\"extra_context\\\" ) :\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"masked_method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"def make_docs_directory(output_dir, name): if not isdir(pjoin(output_dir, name)): subprocess.run([\\\"mkdir\\\", pjoin(output_dir, name)], stdout=subprocess.PIPE) for i in range(10): if not isdir(pjoin(output_dir, name, str(i))): subprocess.run( [\\\"mkdir\\\", pjoin(output_dir, name, str(i))], stdout=subprocess.PIPE )\",\n          \"def merge_dicts(source: Dict, destination: Dict) -> Dict: for key, value in source.items(): if isinstance(value, dict): # get node or create one node = destination.setdefault(key, {}) merge_dicts(value, node) else: destination[key] = value return destination\",\n          \"def assert_results(self, results, activities, msg=\\\"\\\"): activity_ids = [] extra_context = [] for result in results: if hasattr(result, \\\"serialization_id\\\"): activity_ids.append(result.serialization_id) else: activity_ids.append(result) if hasattr(result, \\\"extra_context\\\"): extra_context.append(result.extra_context) compare_lists(activity_ids, [a.serialization_id for a in activities], msg) if extra_context: self.assertEquals([a.extra_context for a in activities], extra_context)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------- Tokenization and Data Wrapping ----------#\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
        "\n",
        "# Constants\n",
        "MAX_INPUT_LEN = 512\n",
        "MAX_TARGET_LEN = 64\n",
        "\n",
        "# Custom dataset for fine-tuning CodeT5\n",
        "class CodeIfDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, source_col='masked_method', target_col='target_block'):\n",
        "        self.inputs = df[source_col].tolist()\n",
        "        self.targets = df[target_col].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.inputs[idx]\n",
        "        target_text = self.targets[idx]\n",
        "\n",
        "        input_enc = self.tokenizer(\n",
        "            input_text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_INPUT_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        target_enc = self.tokenizer(\n",
        "            target_text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_TARGET_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_enc.input_ids.squeeze(),\n",
        "            \"attention_mask\": input_enc.attention_mask.squeeze(),\n",
        "            \"labels\": target_enc.input_ids.squeeze()\n",
        "        }\n",
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = CodeIfDataset(train, tokenizer)\n",
        "valid_dataset = CodeIfDataset(valid, tokenizer)\n",
        "test_dataset = CodeIfDataset(test, tokenizer)"
      ],
      "metadata": {
        "id": "htmFqwGysp67"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------- Finetune Model ----------#\n",
        "\n",
        "# Load the CodeT5-small model\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/CodeBLEU_Project/codet5-if-checkpoints\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=3e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"  # Set to \"wandb\" or \"tensorboard\" if you want visual logs\n",
        ")\n",
        "\n",
        "# Define the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "#Resume training\n",
        "#trainer.train(resume_from_checkpoint= True)"
      ],
      "metadata": {
        "id": "AP1KzSUot59r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "a209bfed-1fb1-4e2e-f414-b0d46602f62e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='43750' max='43750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [43750/43750 : < :, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=43750, training_loss=0.0, metrics={'train_runtime': 0.2729, 'train_samples_per_second': 1282435.429, 'train_steps_per_second': 160304.429, 'total_flos': 4.73696305152e+16, 'train_loss': 0.0, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_export_results(df, output_csv=\"testset-results.csv\"):\n",
        "\n",
        "    # Check required columns\n",
        "    required_cols = [\"input\", \"Predicted full method\", \"Expected full method\"]\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        raise ValueError(f\"DataFrame must contain columns: {required_cols}\")\n",
        "\n",
        "    #Compute F1 Score\n",
        "    y_true = [1] * len(df)\n",
        "    y_pred = [int(p.strip() == r.strip()) for p, r in zip(df[\"Predicted if condition\"], df[\"Expected if condition\"])]\n",
        "    f1 = round(f1_score(y_true, y_pred) * 100, 2)\n",
        "    print(f\"F1 Score (Exact Match): {f1}%\")\n",
        "\n",
        "    # Compute exact match\n",
        "    df[\"Exact match\"] = df[\"Predicted full method\"].str.strip() == df[\"Expected full method\"].str.strip()\n",
        "\n",
        "    # Save refs and hyps to temp files for CodeBLEU\n",
        "    df[\"Expected full method\"].to_csv(\"ref.txt\", index=False, header=False)\n",
        "    df[\"Predicted full method\"].to_csv(\"hyp.txt\", index=False, header=False)\n",
        "\n",
        "    # Load BLEU scorer\n",
        "    bleu = load_metric(\"sacrebleu\")\n",
        "\n",
        "    # BLEU-4 score\n",
        "    predictions = df[\"Predicted full method\"].tolist()\n",
        "    references = [[ref] for ref in df[\"Expected full method\"].tolist()]\n",
        "    bleu_score = bleu.compute(predictions=predictions, references=references)\n",
        "    bleu_score_value = round(bleu_score[\"score\"], 2)\n",
        "\n",
        "    # Run CodeBLEU using subprocess\n",
        "    try:\n",
        "        result = subprocess.check_output(\n",
        "            [\"python\", \"calc_codebleu.py\", \"--ref\", \"ref.txt\", \"--hyp\", \"hyp.txt\", \"--lang\", \"python\"],\n",
        "            cwd=\"/content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU\",\n",
        "            text=True\n",
        "        )\n",
        "        for line in result.splitlines():\n",
        "            if \"CodeBLEU score\" in line:\n",
        "                codebleu_score_value = round(float(line.split(\":\")[-1].strip()), 2)\n",
        "                break\n",
        "        else:\n",
        "            codebleu_score_value = 0.\n",
        "    except Exception as e:\n",
        "        codebleu_score_value = 0.0\n",
        "        print(\"CodeBLEU failed:\", e)\n",
        "\n",
        "\n",
        "\n",
        "    # Add scores to DataFrame\n",
        "    df[\"BLEU-4 prediction score (0-100)\"] = bleu_score_value\n",
        "    df[\"CodeBLEU prediction score (0-100)\"] = codebleu_score_value\n",
        "\n",
        "    # Export final CSV\n",
        "    df[[\n",
        "        \"input\",\n",
        "        \"Exact match\",\n",
        "        \"Expected if condition\",\n",
        "        \"Predicted if condition\",\n",
        "        \"CodeBLEU prediction score (0-100)\",\n",
        "        \"BLEU-4 prediction score (0-100)\"\n",
        "    ]].to_csv(output_csv, index=False)\n",
        "\n",
        "    print(f\"Evaluation complete. Results saved to {output_csv}\")\n",
        "    return output_csv"
      ],
      "metadata": {
        "id": "7q9H4mGjvIuC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------- Evaluation and Prediction ----------#\n",
        "\n",
        "#Make Predicitons\n",
        "model.eval() # Put model in evaluation mode\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "inputs = []\n",
        "\n",
        "# Run prediction loop\n",
        "for batch in DataLoader(test_dataset, batch_size=8):\n",
        "    input_ids = batch[\"input_ids\"].to(model.device)\n",
        "    attention_mask = batch[\"attention_mask\"].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=64)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n",
        "    original_inputs = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
        "\n",
        "    #strips white space\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [label.strip() for label in decoded_labels]\n",
        "    original_inputs = [inp.strip() for inp in original_inputs]\n",
        "\n",
        "    predictions.extend(decoded_preds)\n",
        "    references.extend(decoded_labels)\n",
        "    inputs.extend(original_inputs)\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    \"input\": inputs,                             # masked method with <mask>\n",
        "    \"Expected if condition\": references,         # the original target_block\n",
        "    \"Predicted if condition\": predictions,       # model's generated if\n",
        "    \"Expected full method\": [inp.replace(\"<mask>\", ref) for inp, ref in zip(inputs, references)],\n",
        "    \"Predicted full method\": [inp.replace(\"<mask>\", pred) for inp, pred in zip(inputs, predictions)],\n",
        "})\n"
      ],
      "metadata": {
        "id": "-OG0ADZ4jpiE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_and_export_results(test_df)\n"
      ],
      "metadata": {
        "id": "RwwwskO-j2he",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "dc76f109-fa9b-4860-fc28-69e1656c22e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (Exact Match): 78.82%\n",
            "CodeBLEU failed: Command '['python', 'calc_codebleu.py', '--ref', 'ref.txt', '--hyp', 'hyp.txt', '--lang', 'python']' returned non-zero exit status 2.\n",
            "Evaluation complete. Results saved to testset-results.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'testset-results.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}